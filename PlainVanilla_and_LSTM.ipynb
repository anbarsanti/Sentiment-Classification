{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e343e655-a324-442c-b334-d26ac9a9040a",
   "metadata": {},
   "source": [
    "﷽\n",
    "\n",
    "# Sentiment Classification for IMDB Movie Reviews\n",
    "\n",
    "#### Nurfitri Anbarsanti (G2104045K)\n",
    "\n",
    "<b> An Assignment required in </b><br>\n",
    "<b> EE7207 Neural and Fuzzy Systems </b><br>\n",
    "<b> Lecturer: Nick Luo Wuqiong </b>\n",
    "\n",
    "2023/2024 Semester 2<br>\n",
    "School of Electrical and Electronic Engineering<br>\n",
    "Nanyang Technological University"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad875c05-7af6-4d51-9046-520706600c96",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7962ca-f528-4ea4-a35b-e09c4787bcf8",
   "metadata": {},
   "source": [
    "## Acknowledgement\n",
    "I would like to express my greatest gratitude to Mr. Nick Luo Wuqiong for his excellent support, knowledge, and constant encouragement during the execution of this assignment. His deep knowledge in the subject matter and insightful feedback have not only deepened my comprehension but also significantly improved the standard of my work.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600165fc-2e5c-4e6a-9e14-d791b2336158",
   "metadata": {},
   "source": [
    "## 1. Introduction \n",
    "\n",
    "### 1.1 Recurrent Neural Network<br>\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/5b3c00d462c6e9200315afe46d0093948621eb95/deep-learning/keras-tutorial/imgs/rnn.png\" alt=\"Cat\" style=\"width: 100px;\"/>\n",
    "\n",
    "An RNN is a type of artificial neural network that consists of interconnected units that follow a directed cycle. The network's internal state is established, enabling it to demonstrate dynamic temporal behavior.<br>\n",
    "\n",
    "### 1.2 Backprop Through time\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/5b3c00d462c6e9200315afe46d0093948621eb95/deep-learning/keras-tutorial/imgs/rnn2.png\" alt=\"Cat\" style=\"width: 200px;\"/>\n",
    "\n",
    "In contrast to feed-forward neural networks, recurrent neural networks (RNNs) has the capability to encode longer historical information, making them particularly well-suited for sequential models. The Backpropagation Through Time expands upon the standard Backpropagation method to accommodate the building of recurrent neural networks.\n",
    "\n",
    "### 1.3 Sentiment Classification\n",
    "\n",
    "This study will build a sentiment classifier using at least, Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks. Both are powerful approaches in the field of natural language processing (NLP) for determining the emotional tone behind a sequence of text. We utilize dataset stored as CSV files containing movie reviews from IMDB. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fcb27c-277c-4020-be88-8f7988dc1fe7",
   "metadata": {},
   "source": [
    "## 2. Methods\n",
    "\n",
    "### 2.1 Dataset\n",
    "\n",
    "In this study, we are given a set of training data from the file named `movie_train.csv` that has textual reviews of movies, accompanied by their respective sentiment labels. Every row in the dataset corresponds to a review, and the corresponding sentiment label is included. The file named `movie_test.csv` provides the test data. \n",
    "\n",
    "The training data consists of $32,000$ data, and their dimension is padded to their maximum length. The training data is complemented with their label, which consists of $32,000$ labels as well, and its dimension is $1$. The labels are either $0$ or $1$. The label $0$ means its sentiment is `negative`, and the label $1$ means that its sentiment is `positive`.\n",
    "\n",
    "We are also given a set of testing data from `movie_test.csv`, which consists of $8,000$ in data, and their dimension is padded to their maximum length. Its labels' dimension is $1$ as well.\n",
    "\n",
    "The dataset is divided into $80\\%$ for the training set and the rest of $20\\%$ for the validation data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3462d92-946f-4bb8-8a50-e82caf14ae1d",
   "metadata": {},
   "source": [
    "### 2.2 Experimental Setting\n",
    "\n",
    "The Jupyter Notebook is installed locally, which hopefully gives us more flexibility, although it requires more effort to configure it. In this study, we set our own environment using the `conda` environment. The necessary dependencies are Python, Tensorflow, and Keras. \n",
    "\n",
    "TensorFlow is one of the earliest deep-learning frameworks and has a mature ecosystem with extensive documentation, tutorials, and resources. Keras, now tightly integrated into TensorFlow, provides a high-level API for building and training neural networks, making it easy to prototype and experiment with different architectures quickly. In this study, we choose Tensorflow and Keras to build the RNN sentiment classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770139e7-b01d-4e7c-8c82-a3e26b61c488",
   "metadata": {},
   "source": [
    "### 2.3 Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bd0e9f11-d37b-4906-b569-c5ded6db6a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, SimpleRNN, Embedding, LSTM, GRU, Dropout, Bidirectional\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee403ba7-2f4c-4947-be6f-cbc951ccb842",
   "metadata": {},
   "source": [
    "### 2.4. Data Loading and Cleaning\n",
    "\n",
    "The implementation of preprocessing techniques on input text before its utilization with Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks plays a pivotal role in enhancing the efficiency of these models in addressing natural language processing tasks. The primary objective of preprocessing is to transform unprocessed text into a structured format that can be read and analyzed by the models.\n",
    "\n",
    "<u>Data Loading</u>\n",
    "\n",
    "Pandas library has been imported, and the `read_csv` function is used to load the CSV file. The labels are converted from the categorized form into a number form using `fit_transform function`.\n",
    "\n",
    "<u>Text Cleaning</u>\n",
    "\n",
    "In this step, we remove and replace symbols (`<br>`, `</br>` and `<br />`) and special characters that are not relevant to the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5710ac5c-36cf-4cd0-bf6f-82c9f616d9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Training Dataset\n",
    "data_train = pd.read_csv('movie_train.csv')\n",
    "data_train_text = data_train.iloc[:,0]\n",
    "data_train_label = data_train.iloc[:,1]\n",
    "data_train_label = np.array(data_train_label)\n",
    "data_train_label = LabelEncoder().fit_transform(data_train_label)\n",
    "\n",
    "# Load the Testing Dataset\n",
    "data_test = pd.read_csv('movie_test.csv')\n",
    "data_test_text = data_test.iloc[:,0]\n",
    "data_test_label = data_test.iloc[:,1]\n",
    "data_test_label = np.array(data_test_label)\n",
    "data_test_label = LabelEncoder().fit_transform(data_test_label)\n",
    "\n",
    "# Data Preprocess to remove \"<br> and </br>\" in the Training data texts\n",
    "data_train_text = data_train_text.str.replace('<br>','')\n",
    "data_train_text = data_train_text.str.replace('</br>','')\n",
    "data_train_text = data_train_text.str.replace('<br />','')\n",
    "\n",
    "# Data Preprocess to remove \"<br> and </br>\" in the Testing data texts\n",
    "data_test_text = data_test_text.str.replace('<br>','')\n",
    "data_test_text = data_test_text.str.replace('</br>','')\n",
    "data_test_text = data_test_text.str.replace('<br />','')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70115005-b645-4bb1-b643-d94106043906",
   "metadata": {},
   "source": [
    "### 2.5. Tokenization\n",
    "\n",
    "The training data should be tokenized. We are using the TensorFlow (Keras) Tokenizer class. Initially, we instantiate the Tokenizer object, which determines the maximum number of words to retain in our vocabulary following tokenization. Additionally, we assign an out-of-vocabulary token to encode test data words that we have not encountered during our training. Without this token, these previously unseen words would be automatically excluded from our vocabulary and remain unaccounted for.\n",
    "\n",
    "<b>2.5.1. Obtain the word index</b>\n",
    "\n",
    "One consequence of the tokenization procedure is generating a word index, which establishes a correspondence between words in our lexicon and their numerical representation. \n",
    "\n",
    "<b>2.5.2. Encoding the training data sentences into sequences </b>\n",
    "\n",
    "In this process, we transform our textual statements from \"My name is Matthew\" to \"6 8 2 19,\" where each number corresponds to the appropriate words in the index. Given that neural networks operate by executing numerical computations, it is not feasible to input a collection of words.\n",
    "\n",
    "<b>2.5.3. Determine the maximum length of the training sequence</b>\n",
    "\n",
    "We opt to identify the longest encoded sequence and utilize it as the maximum length for our sequence. Various justifications exist for refraining from engaging in this behavior; nevertheless, there are other instances where it might be deemed suitable. The `maxlentrain` and `maxlentest` variable is subsequently employed in the actual padding of the training sequence and the testing sequence subsequently. \n",
    "\n",
    "<b>2.5.4. Padding the sequences</b>\n",
    "\n",
    "As previously stated, our encoded sequences must have identical lengths. We have determined the length of the longest sequence and will utilize it to append additional '0's at the end ('post') to all subsequent sequences. Additionally, we will terminate any sequences that exceed the maximum length from the end ('post'). To achieve this, we utilize the TensorFlow (Keras) pad_sequences module. Refer to the manual for supplementary padding alternatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fb1afb86-5a3f-4241-924d-d61dc2829fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit the tokenizer\n",
    "tokenizer = Tokenizer(num_words=1000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(data_train_text)\n",
    "\n",
    "# Get our training data word index\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Convert sentences to sequences of integers\n",
    "data_train_sequences = tokenizer.texts_to_sequences(data_train_text)\n",
    "\n",
    "# Get max training sequence length\n",
    "maxlentrain = max([len(x) for x in data_train_sequences])\n",
    "\n",
    "# Pad sequences to ensure uniform length\n",
    "data_train_padded = pad_sequences(data_train_sequences, padding='post', maxlen=maxlentrain)\n",
    "\n",
    "# Step 2-B: Tokenization for testing data\n",
    "# Initialize and fit the tokenizer\n",
    "# oov_token = <UNK>\n",
    "tokenizer = Tokenizer(num_words=1000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(data_test_text)\n",
    "\n",
    "# Get our training data word index\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Convert sentences to sequences of integers\n",
    "data_test_sequences = tokenizer.texts_to_sequences(data_test_text)\n",
    "\n",
    "# Get max training sequence length\n",
    "maxlentest = max([len(x) for x in data_test_sequences])\n",
    "\n",
    "# Pad sequences to ensure uniform length\n",
    "data_test_padded = pad_sequences(data_test_sequences, padding='post', maxlen=maxlentest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81207501-2d40-4bfd-a68c-7320620c948a",
   "metadata": {},
   "source": [
    "<b>2.5.6. Check the tokenized and padded data</b>\n",
    "\n",
    "In this step, we are checking the type, shape, and padded results of our data. We also check the sample of untokenized training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b67d8f0a-28d8-4c1b-ae4f-97ed809b5f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Data ---\n",
      "\n",
      "One example of the training data text:\n",
      " The film Classe tous risques directed by Claude Sautet was not a film, to be honest, I had ever really heard of until the Film Forum in NYC said that they would have a 2-week screening of the film, with new English subtitles. When I also read that it was in the vein of the classic French crime films ala Jean Pierre Melville, I jumped at the chance to check it out (at best it would rank up with his great works, and at worst I would get some good popcorn in a great theater). It was well worth the admission, as Classe tous risques is one of those kinds of French films that is just waiting to be re-discovered (or discovered for the first time). With terrific, tense diligence, Sautet keeps the suspense at a tight pitch for the first forty minutes of the film, keeping a good (if not great) middle section, and then ending it up with what is always expected with these films, but with fascinating motivations by way of the characters. With a film in the vein of this sort, you know how it will end, but it's the cool, observant journey that counts.The film features a performance with some real truth and honesty, amid the \"old-school\" criminal's code, by Lino Ventura as Aldo, who at the start of the film (one of the best beginnings to a film in this genre and country) steals a hefty amount of money with his partner in crime). When there is a sudden, ugly twist of fate on a beach late one night, Aldo is again on the run with two little kids. He gets the aid of Eric Stark (Jean-Paul Belmondo, a role in tune with Le Doulos only with a smidgen more humanity and charisma), who is also a thief and drives him into Paris. But there are some problems with some of Aldo's old business partner's, and one old score may be just the right ticket. A couple of times the plot may seem to be leisurely, but it isn't. Like Melville, Sautet doesn't allow any fat to his story, and it's a very tightly structured film, with some good doses of humor here and there (I was sometimes grinning at the audacity of the criminals in the beginning chase sequence, and also with a particular woman who had a finicky thing with her cat and a fish).Along with a fine score by the great George Delerue, exceptional cinematography, and a mood that is seldom met let alone matched now adays, Classe tous risques is a reminder of that bridge between the real old-school film-noir, and the latter day crime films. Gangsters in these new sort of \"thug-life\" movies have a 1000th of the class and honor of the thieves in this film, and is a second banana to the works of Melville and Jules Dassin (a compliment I assure you). That it has a good realistic, moral edge helps as well.\n",
      "\n",
      "Padded training sequences:\n",
      " [[940   1   3 ...   0   0   0]\n",
      " [ 81  16 421 ...   0   0   0]\n",
      " [ 10 423 263 ...   0   0   0]\n",
      " ...\n",
      " [105 152 100 ...   0   0   0]\n",
      " [145 757  18 ...   0   0   0]\n",
      " [134  10 247 ...   0   0   0]]\n",
      "\n",
      "Padded training sequences shape: (32000, 2246)\n",
      "\n",
      "Padded Training sequences data type: <class 'numpy.ndarray'>\n",
      "\n",
      "--- Training Label ---\n",
      "\n",
      "One example of the training label text:\n",
      " 1\n",
      "\n",
      "Training Label type: <class 'numpy.ndarray'>\n",
      "\n",
      "Training Label shape: (32000,)\n",
      "\n",
      "--- Testing Data ---\n",
      "\n",
      "Padded testing sequences:\n",
      " [[144   8   1 ...   0   0   0]\n",
      " [111   1   5 ...   0   0   0]\n",
      " [ 11  17   7 ...   0   0   0]\n",
      " ...\n",
      " [ 46  23 151 ...   0   0   0]\n",
      " [ 10  39 406 ...   0   0   0]\n",
      " [144  22 250 ...   0   0   0]]\n",
      "\n",
      "Padded testing sequences shape: (8000, 2466)\n",
      "\n",
      "Padded testing sequences data type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Check the results of our work\n",
    "print(\"\\n--- Training Data ---\")\n",
    "print(\"\\nOne example of the training data text:\\n\", data_train_text[45])\n",
    "# print(\"\\nTraining sequences data:\\n\", data_train_sequences)\n",
    "print(\"\\nPadded training sequences:\\n\", data_train_padded)\n",
    "print(\"\\nPadded training sequences shape:\", data_train_padded.shape)\n",
    "print(\"\\nPadded Training sequences data type:\", type(data_train_padded))\n",
    "print(\"\\n--- Training Label ---\")\n",
    "print(\"\\nOne example of the training label text:\\n\", data_train_label[45])\n",
    "print(\"\\nTraining Label type:\", type(data_train_label))\n",
    "print(\"\\nTraining Label shape:\", data_train_label.shape)\n",
    "print(\"\\n--- Testing Data ---\")\n",
    "print(\"\\nPadded testing sequences:\\n\", data_test_padded)\n",
    "print(\"\\nPadded testing sequences shape:\", data_test_padded.shape)\n",
    "print(\"\\nPadded testing sequences data type:\", type(data_test_padded))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42352f44-b613-43ea-b52e-7dd7f64ee466",
   "metadata": {},
   "source": [
    "### 2.6. Sentiment Classification using Plain Vanilla RNN model\n",
    "\n",
    "A SimpleRNN model is a particular kind of Recurrent Neural Network (RNN) that is specifically built to handle sequential data by retaining its internal state as a form of memory for prior inputs. The term \"simple\" describes this sort of RNN since it lacks the intricate mechanics present in more advanced RNNs such as LSTMs or GRUs.\n",
    "\n",
    "SimpleRNNs can be used for predicting future values in a time series based on past observations. They can also be used for tasks like sentiment analysis, where the sequence of words in a sentence needs to be processed to determine the sentiment.\n",
    "\n",
    "<img src=\"https://github.com/matakshay/IMDB_Sentiment_Analysis/blob/master/RNN.png?raw=true\" alt=\"LSTM\" style=\"width: 400px;\">\n",
    "Fig. Diagram of a Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c81124bb-6ae0-4c23-a151-551c9f97b76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_18\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_18\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2246</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">320,000</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_18 (\u001b[38;5;33mEmbedding\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2246\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │         \u001b[38;5;34m320,000\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_8 (\u001b[38;5;33mSimpleRNN\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">322,113</span> (1.23 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m322,113\u001b[0m (1.23 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">322,113</span> (1.23 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m322,113\u001b[0m (1.23 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "# Building the Plain Vanilla RNN model\n",
    "\n",
    "# Define parameters\n",
    "n_timesteps = data_train_padded.shape[0] # number of samples \n",
    "n_features = data_train_padded.shape[1]  # length of our input sequences after preprocessing (padding)\n",
    "n_outputs = data_train_label.shape[0]\n",
    "vocab_size = 10000\n",
    "embd_len = 32\n",
    "\n",
    "# Define the models\n",
    "vanillaRNN = Sequential()\n",
    "vanillaRNN.add(Embedding(input_dim=vocab_size, \n",
    "                         output_dim=embd_len, \n",
    "                         input_shape=(n_features,)))\n",
    "vanillaRNN.add(SimpleRNN(32, input_shape=(n_features,), \n",
    "                         return_sequences=False))\n",
    "vanillaRNN.add(Dense(1, activation ='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "vanillaRNN.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "print(vanillaRNN.summary())\n",
    "\n",
    "# Check\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df2f86f-ae5b-4527-865f-f76c88da5f78",
   "metadata": {},
   "source": [
    "The model is trained on a subset of the IMDB dataset, using binary cross-entropy as the loss function and accuracy as the evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5af0554c-4d7f-4731-9e9b-1c3c8391344b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-05 15:03:51.385863\n",
      "Epoch 1/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m400s\u001b[0m 400ms/step - accuracy: 0.5023 - loss: 0.6938\n",
      "Epoch 2/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m412s\u001b[0m 412ms/step - accuracy: 0.4994 - loss: 0.6938\n",
      "Epoch 3/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m397s\u001b[0m 397ms/step - accuracy: 0.5027 - loss: 0.6937\n",
      "Epoch 4/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m400s\u001b[0m 400ms/step - accuracy: 0.4979 - loss: 0.6938\n",
      "Epoch 5/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m435s\u001b[0m 435ms/step - accuracy: 0.4966 - loss: 0.6936\n",
      "Epoch 6/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m421s\u001b[0m 420ms/step - accuracy: 0.5005 - loss: 0.6935\n",
      "Epoch 7/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 426ms/step - accuracy: 0.5022 - loss: 0.6936\n",
      "Epoch 8/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 414ms/step - accuracy: 0.4916 - loss: 0.6938\n",
      "Epoch 9/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 408ms/step - accuracy: 0.4995 - loss: 0.6934\n",
      "Epoch 10/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m384s\u001b[0m 384ms/step - accuracy: 0.4939 - loss: 0.6935\n",
      "2024-04-05 16:12:09.163117\n"
     ]
    }
   ],
   "source": [
    "# Train the Plain Vanilla RNN model\n",
    "print(datetime.now())\n",
    "history = vanillaRNN.fit(data_train_padded, data_train_label, epochs=10, batch_size=32)\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241da043-4814-4c65-be14-744c24567cbf",
   "metadata": {},
   "source": [
    "### 2.7. The Performance of Plain Vanilla RNN model\n",
    "\n",
    "The Plain Vanilla RNN (SimpleRNN) model achieved an accuracy of $50.05 \\%$ on the IMDB movie reviews dataset. The lowest loss recorded is $69.34 \\%$\n",
    "\n",
    "The vanishing gradient problem is a common issue encountered by SimpleRNNs, resulting in reduced efficacy in capturing long-term dependencies inside sequences.\n",
    "\n",
    "**Accuracy**\n",
    "\n",
    "RNNs are generally most likely to be outperformed by LSTMs and GRUs in tasks that require understanding longer contexts, such as sentiment analysis of movie reviews. \n",
    "\n",
    "**Training Time**\n",
    "\n",
    "RNNs can be trained relatively quickly due to their more straightforward structure, but they may require more epochs to reach the same level of accuracy as LSTMs or GRUs.\n",
    "\n",
    "**Model Size**\n",
    "\n",
    "RNNs have fewer parameters than LSTMs and GRUs, leading to a smaller model size. However, their performance on complex tasks like sentiment analysis may be limited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3dd539aa-0add-40c1-82ba-7e4d912aa0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.5003 - loss: 0.6932\n",
      "Test loss, Test accuracy: [0.693122923374176, 0.5040000081062317]\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 53ms/step\n",
      "[[4031    0]\n",
      " [3969    0]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = vanillaRNN.evaluate(data_test_padded, data_test_label, batch_size=128)\n",
    "print(\"Test loss, Test accuracy:\", results)\n",
    "\n",
    "# Plot confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Predict the probabilities for the test data\n",
    "probabilities = vanillaRNN.predict(data_test_padded)\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "predictions = np.argmax(probabilities, axis=1)\n",
    "\n",
    "# Compute the confusion matrix using TensorFlow\n",
    "conf_matrix = tf.math.confusion_matrix(data_test_label, predictions)\n",
    "\n",
    "# To print the confusion matrix, you need to run it within a TensorFlow session (for TensorFlow 1.x)\n",
    "# For TensorFlow 2.x, you can directly print it as it executes eagerly\n",
    "print(conf_matrix.numpy())\n",
    "\n",
    "# Assuming conf_matrix is the confusion matrix obtained from TensorFlow\n",
    "conf_matrix_np = conf_matrix.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1962eb07-554a-4576-8913-ca0e84012cdf",
   "metadata": {},
   "source": [
    "In this study, we use a confusion matrix that summarizes the performance of the Plain Vanilla RNN model as below. \n",
    "\n",
    "The confusion matrix displays the number of instances the model produces on the test data.\n",
    "\n",
    "- True positives (TP): occur when the Plain Vanilla RNN model accurately predicts a positive data point.\n",
    "- True negatives (TN): occur when the Plain Vanilla RNN model accurately predicts a negative data point.\n",
    "- False positives (FP): occur when the Plain Vanilla RNN model predicts a positive data point incorrectly.\n",
    "- False negatives (FN): occur when the Plain Vanilla RNN model mispredicts a negative data point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a29faf-9f93-4f40-a21c-1e4fa918c914",
   "metadata": {},
   "source": [
    "### 2.8. Sentiment Classification using LSTM model\n",
    "\n",
    "LSTM networks are a particular Recurrent Neural Network (RNN) structure employed in deep learning to handle sequential input. They excel at tasks that involve groups of text, such as sentiment analysis of movie reviews. \n",
    "\n",
    "LSTMs, in contrast to basic RNNs, are specifically engineered to circumvent the issue of vanishing gradients, enabling them to capture enduring relationships within textual data effectively.\r\n",
    "LSTMs can process input sequences of varying lengths, which is important for analyzing movie reviews that can vary significantly in length. \n",
    "\n",
    "<img src=\"https://github.com/matakshay/IMDB_Sentiment_Analysis/blob/master/LSTM.png?raw=true\" alt=\"LSTM\" style=\"width: 400px;\"/>\n",
    "\n",
    "LSTMs often use an **embedding layer** at the input, transforming words into dense vectors of fixed size. This captures semantic relationships between words and improves the model's ability to learn from the text data.\n",
    "\n",
    "LSTMs process text data sequentially, one word at a time, maintaining a hidden state that effectively summarizes the information seen so far. This allows the model to make predictions based on the entire context of a sentence or document.\n",
    "\n",
    "The model is shown in the figure below. \n",
    "\n",
    "<img src=\"https://github.com/matakshay/IMDB_Sentiment_Analysis/blob/master/LSTM_model_visual.png?raw=true\" alt=\"LSTM\" style=\"width: 350px;\"/>\n",
    "Diagram of an LSTM Network\n",
    ",\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7f15b0f4-e59e-4af1-b740-97075bbce0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_21\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_21\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2246</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">160,000</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">164,864</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_21 (\u001b[38;5;33mEmbedding\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2246\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │         \u001b[38;5;34m160,000\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m164,864\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m16,448\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">343,425</span> (1.31 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m343,425\u001b[0m (1.31 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">343,425</span> (1.31 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m343,425\u001b[0m (1.31 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "# Building the LSTM model\n",
    "\n",
    "# Define parameters\n",
    "n_timesteps = data_train_padded.shape[0] # number of samples \n",
    "n_features = data_train_padded.shape[1]  # length of our input sequences after preprocessing (padding)\n",
    "n_outputs = data_train_label.shape[0]\n",
    "vocab_size = 5000\n",
    "embd_len = 32\n",
    "\n",
    "# Define the models\n",
    "thisLSTM = Sequential()\n",
    "thisLSTM.add(Embedding(input_dim=vocab_size, \n",
    "                       output_dim = 32, \n",
    "                       input_shape=(n_features,)))\n",
    "thisLSTM.add(Bidirectional(LSTM(units=128,\n",
    "                                activation='tanh',\n",
    "                                recurrent_activation='sigmoid',\n",
    "                                dropout=0.0,\n",
    "                                recurrent_dropout=0.0,\n",
    "                                return_sequences = False)))\n",
    "thisLSTM.add(Dense(units=64,\n",
    "                   activation ='relu'))\n",
    "thisLSTM.add(Dropout(0.3))\n",
    "thisLSTM.add(Dense(units=32,\n",
    "                   activation='relu'))\n",
    "thisLSTM.add(Dense(units=1,\n",
    "                   activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "thisLSTM.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "print(thisLSTM.summary())\n",
    "\n",
    "# Check\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac623d6-b760-45c7-b43d-47daece279f1",
   "metadata": {},
   "source": [
    "The model is trained on a subset of the IMDB dataset, using binary cross-entropy as the loss function and accuracy as the evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ae92d648-aaed-4beb-961c-6deb21317546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time = 2024-04-05 16:28:53.237997\n",
      "Epoch 1/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8203s\u001b[0m 16s/step - accuracy: 0.5114 - loss: 0.6948 - val_accuracy: 0.5039 - val_loss: 0.6930\n",
      "Epoch 2/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8290s\u001b[0m 17s/step - accuracy: 0.5161 - loss: 0.6923 - val_accuracy: 0.5345 - val_loss: 0.6906\n",
      "Epoch 3/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17s/step - accuracy: 0.6309 - loss: 0.6387 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[109], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the LSTM model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime =\u001b[39m\u001b[38;5;124m\"\u001b[39m, datetime\u001b[38;5;241m.\u001b[39mnow())\n\u001b[1;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m thisLSTM\u001b[38;5;241m.\u001b[39mfit(data_train_padded, data_train_label, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(data_test_padded, data_test_label))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime =\u001b[39m\u001b[38;5;124m\"\u001b[39m, datetime\u001b[38;5;241m.\u001b[39mnow())\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\pytorchbook\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\pytorchbook\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:351\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_epoch_iterator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_epoch_iterator \u001b[38;5;241m=\u001b[39m TFEpochIterator(\n\u001b[0;32m    342\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m    343\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    349\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    350\u001b[0m     )\n\u001b[1;32m--> 351\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[0;32m    352\u001b[0m     x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m    353\u001b[0m     y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m    354\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39mval_sample_weight,\n\u001b[0;32m    355\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mvalidation_batch_size \u001b[38;5;129;01mor\u001b[39;00m batch_size,\n\u001b[0;32m    356\u001b[0m     steps\u001b[38;5;241m=\u001b[39mvalidation_steps,\n\u001b[0;32m    357\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    358\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    359\u001b[0m     _use_cached_eval_dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    360\u001b[0m )\n\u001b[0;32m    361\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    363\u001b[0m }\n\u001b[0;32m    364\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\pytorchbook\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\pytorchbook\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:437\u001b[0m, in \u001b[0;36mTensorFlowTrainer.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    436\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m--> 437\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_function(iterator)\n\u001b[0;32m    438\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_end(step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs))\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_evaluating:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\pytorchbook\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\pytorchbook\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\pytorchbook\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\pytorchbook\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\pytorchbook\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\pytorchbook\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\pytorchbook\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\pytorchbook\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1501\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1502\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1503\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1504\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1505\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1506\u001b[0m   )\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\pytorchbook\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the LSTM model\n",
    "print(\"Time =\", datetime.now())\n",
    "history = thisLSTM.fit(data_train_padded, data_train_label, epochs=10, batch_size=64, validation_data=(data_test_padded, data_test_label))\n",
    "print(\"Time =\", datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7aed231-dda6-4bb3-9de8-993b6e5e6e09",
   "metadata": {},
   "source": [
    "### 2.9. The Performance of LSTM model\n",
    "\n",
    "The LSTM model achieved an accuracy that will be higher than SimpleRNN model, which is $63.09 \\%$ on the IMDB movie reviews dataset. The lowest loss recorded is $63.87 \\%$, lower than SimpleRNN model. \n",
    "\n",
    "LSTM models can process long sequences of text and handle the vanishing gradient problem that affects standard RNNs.\n",
    "\n",
    "**Accuracy**\n",
    "\n",
    "Based on this experience, the LSTM model performs better on the IMDB dataset than the SimpleRNN or the Plain Vanilla RNN model.\n",
    "\n",
    "**Training Time**\n",
    "\n",
    "The training time of the LSTM model requires a very long time and a lot of processing resources. \n",
    "\n",
    "**Model Size**\n",
    "\n",
    "LSTMs typically have a larger number of parameters due to their complex gating mechanisms, which can lead to a larger model size. However, specific details on the model size in the context of the IMDB dataset are not provided in the search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8be30687-bc94-41c1-b281-f02d422c087a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 751ms/step - accuracy: 0.5676 - loss: 0.7678\n",
      "Test loss, Test accuracy: [0.7769380211830139, 0.5644999742507935]\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 396ms/step\n",
      "[[4031    0]\n",
      " [3969    0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = thisLSTM.evaluate(data_test_padded, data_test_label, batch_size=128)\n",
    "print(\"Test loss, Test accuracy:\", results)\n",
    "\n",
    "# Plot confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Predict the probabilities for the test data\n",
    "probabilities = thisLSTM.predict(data_test_padded)\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "predictions = np.argmax(probabilities, axis=1)\n",
    "\n",
    "# Compute the confusion matrix using TensorFlow\n",
    "conf_matrix = tf.math.confusion_matrix(data_test_label, predictions)\n",
    "\n",
    "# To print the confusion matrix, you need to run it within a TensorFlow session (for TensorFlow 1.x)\n",
    "# For TensorFlow 2.x, you can directly print it as it executes eagerly\n",
    "print(conf_matrix.numpy())\n",
    "\n",
    "# Assuming conf_matrix is the confusion matrix obtained from TensorFlow\n",
    "conf_matrix_np = conf_matrix.numpy()\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(conf_matrix_np, annot=True, fmt='g')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44639603-60b3-43f1-a5f7-58781813537e",
   "metadata": {},
   "source": [
    "In this study, we use a confusion matrix that summarizes the performance of the Plain Vanilla RNN model as below. \n",
    "\n",
    "The confusion matrix displays the number of instances the model produces on the test data.\n",
    "\n",
    "- True positives (TP): occur when the Plain Vanilla RNN model accurately predicts a positive data point.\n",
    "- True negatives (TN): occur when the Plain Vanilla RNN model accurately predicts a negative data point.\n",
    "- False positives (FP): occur when the Plain Vanilla RNN model predicts a positive data point incorrectly.\n",
    "- False negatives (FN): occur when the Plain Vanilla RNN model mispredicts a negative data point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4417b114-bb30-4a38-96dc-b33c0102930c",
   "metadata": {},
   "source": [
    "====================================\n",
    "==================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8938b072-e5ef-46d2-9302-912983631fa6",
   "metadata": {},
   "source": [
    "# to be continued to `GRU.ipynb`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fc6a34-1aa6-4a7e-9a08-1d9664c2125b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
